{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "  The project aims to analyze and predict passenger satisfaction with their airline travel experience using machine learning techniques. It utilizes a dataset containing various attributes related to passengers' demographics, travel preferences, flight details, and ratings for different services provided during the flight. By leveraging this dataset, the project seeks to understand the factors that influence passenger satisfaction and develop predictive models to forecast whether a passenger will be satisfied or dissatisfied based on their characteristics and flight-related factors.\n",
    "\n",
    "  The project likely involves several steps, including data preprocessing, exploratory data analysis (EDA), feature engineering, model selection, training, and evaluation. Machine learning algorithms such as decision trees, possibly with Gini index or entropy as splitting criteria, are employed to build predictive models. These models are then evaluated using performance metrics such as accuracy, precision, recall, and F1-score to assess their effectiveness in predicting passenger satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airplane\n",
    "\n",
    "The CSV file contains detailed information about airline passengers' travel experiences and satisfaction levels. Each row in the CSV file represents a single passenger's feedback, while the columns represent different attributes and ratings associated with their travel experience. Key attributes include passenger demographics (e.g., gender, age), travel details (e.g., flight distance, type of travel), and ratings for various services provided during the flight (e.g., seat comfort, inflight entertainment). Additionally, the file includes columns for departure and arrival delays and the overall satisfaction level of passengers.\n",
    "\n",
    "The dataset serves as the primary source of information for the project, providing valuable insights into passenger preferences, behaviors, and satisfaction levels. It is used for exploratory data analysis, feature engineering, model training, and evaluation to develop effective predictive models for understanding and predicting passenger satisfaction with airline travel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"csv/Airplane.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting non-numeric values to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"satisfaction\"] = data[\"satisfaction\"].map({\"neutral or dissatisfied\": 0, \"satisfied\": 1}).astype(int)\n",
    "data[\"Customer Type\"] = data[\"Customer Type\"].map({\"disloyal Customer\": 0, \"Loyal Customer\": 1}).astype(int)\n",
    "data[\"Type of Travel\"] = data[\"Type of Travel\"].map({\"Personal Travel\": 0, \"Business travel\": 1}).astype(int)\n",
    "data[\"Gender\"] = data[\"Gender\"].map({\"Female\": 0, \"Male\": 1}).astype(int)\n",
    "data[\"Class\"] = data[\"Class\"].map({\"Eco\": 0, \"Eco Plus\": 1, \"Business\": 2}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Categorizing continuous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* -- Arrival Delay in Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Arrival Delay in Minutes\"] <= 5, \"Arrival Delay in Minutes\"] = 0\n",
    "data.loc[(data[\"Arrival Delay in Minutes\"] > 5), \"Arrival Delay in Minutes\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* -- Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Age\"] <= 20, \"Age\"] = 0\n",
    "data.loc[(data[\"Age\"] > 20) & (data[\"Age\"] <= 39), \"Age\"] = 1\n",
    "data.loc[(data[\"Age\"] > 39) & (data[\"Age\"] <= 60), \"Age\"] = 2\n",
    "data.loc[(data[\"Age\"] > 60), \"Age\"] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* -- Cleanliness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Cleanliness\"] < 3, \"Cleanliness\"] = 0\n",
    "data.loc[data[\"Cleanliness\"] == 3, \"Cleanliness\"] = 1\n",
    "data.loc[(data[\"Cleanliness\"] > 3), \"Cleanliness\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* -- Flight Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Flight Distance\"] <= 1000, \"Flight Distance\"] = 0\n",
    "data.loc[(data[\"Flight Distance\"] > 1000) & (data[\"Flight Distance\"] <= 2000), \"Flight Distance\"] = 1\n",
    "data.loc[(data[\"Flight Distance\"] > 2000) & (data[\"Flight Distance\"] <= 3000), \"Flight Distance\"] = 2\n",
    "data.loc[(data[\"Flight Distance\"] > 3000), \"Flight Distance\"] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* -- Departure Delay in Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Departure Delay in Minutes\"] <= 5, \"Departure Delay in Minutes\"] = 0\n",
    "data.loc[(data[\"Departure Delay in Minutes\"] > 5) & (data[\"Departure Delay in Minutes\"] <= 25), \"Departure Delay in Minutes\"] = 1\n",
    "data.loc[(data[\"Departure Delay in Minutes\"] > 25), \"Departure Delay in Minutes\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Selecting the last 10,000 rows as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.tail(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removing the last 10,000 rows from the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.head(90000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Separating data for satisfied and neutral or dissatisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfaction_0 = data[data['satisfaction'] == 0]\n",
    "satisfaction_1 = data[data['satisfaction'] == 1]\n",
    "random.seed(43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Selecting 10,000 random samples from each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfaction_0_random = random.sample(satisfaction_0.index.tolist(), 10000)\n",
    "satisfaction_1_random = random.sample(satisfaction_1.index.tolist(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Combining these two data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data.loc[satisfaction_0_random], data.loc[satisfaction_1_random]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"index\", \"id\", \"Gender\"], axis=1)\n",
    "test = test.drop([\"index\", \"id\", \"Gender\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* show clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is not shown due to large size\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  satisfaction\n",
      "0    0      0.245791\n",
      "1    1      0.456366\n",
      "2    2      0.634953\n",
      "3    3      0.253857\n"
     ]
    }
   ],
   "source": [
    "print(data[[\"Age\",\"satisfaction\"]].groupby([\"Age\"],as_index=False).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"csv/Restaurant.csv\");\n",
    "# test = data.tail(1);\n",
    "# data = data.head(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, feature=None, value=None, subtrees=None):\n",
    "        self.feature = feature\n",
    "        self.value = value # for leaf node\n",
    "        self.subtrees = subtrees if subtrees is not None else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gini index / Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gini index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Gini index\n",
    "def calculate_gini(labels):\n",
    "    total_samples = len(labels)\n",
    "    if total_samples is None:\n",
    "        return 0\n",
    "    \n",
    "    gini = 1\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    for count in counts:\n",
    "        probability = count / total_samples\n",
    "        gini -= probability ** 2\n",
    "    # This part is written based on the mathematical formula of the Gini index\n",
    "    return gini\n",
    "\n",
    "# Function to select the feature with the best Gini index\n",
    "def best_feature_gini(df, target_name):\n",
    "    best_feature = None\n",
    "    min_gini = float('inf')\n",
    "    \n",
    "    # This loop checks all features present in the input DataFrame\n",
    "    for feature in df.columns:\n",
    "        if feature == target_name:\n",
    "            continue\n",
    "        \n",
    "        # All possible values of a feature are stored in this variable\n",
    "        unique_values = df[feature].unique()\n",
    "        weighted_gini = 0\n",
    "        \n",
    "        # Calculate Gini for all possible values\n",
    "        for value in unique_values:\n",
    "            subset = df[df[feature] == value]\n",
    "            subset_size = len(subset)\n",
    "            subset_gini = calculate_gini(subset[target_name])\n",
    "            weighted_gini += (subset_size / len(df)) * subset_gini\n",
    "        \n",
    "        # If the calculated Gini is less than the minimum Gini, update the minimum value\n",
    "        if weighted_gini < min_gini:\n",
    "            min_gini = weighted_gini\n",
    "            best_feature = feature\n",
    "    \n",
    "    return best_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(labels):\n",
    "    total_samples = len(labels)\n",
    "    if total_samples == 0:\n",
    "        return 0\n",
    "    \n",
    "    entropy = 0\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    for count in counts:\n",
    "        probability = count / total_samples\n",
    "        entropy -= probability * np.log2(probability)\n",
    "    # This loop implements the entropy formula\n",
    "    return entropy\n",
    "\n",
    "# Function to select the best feature using entropy\n",
    "def best_feature_entropy(df, target_name):\n",
    "    best_feature = None\n",
    "    min_entropy = float('inf')\n",
    "    \n",
    "    # This loop checks all features present in the input DataFrame\n",
    "    for feature in df.columns:\n",
    "        if feature == target_name:\n",
    "            continue\n",
    "        \n",
    "        # All possible values of a feature are stored in this variable\n",
    "        unique_values = df[feature].unique()\n",
    "        weighted_entropy = 0\n",
    "        \n",
    "        # Calculate entropy for all possible values\n",
    "        for value in unique_values:\n",
    "            subset = df[df[feature] == value]\n",
    "            subset_size = len(subset)\n",
    "            subset_entropy = calculate_entropy(subset[target_name])\n",
    "            weighted_entropy += (subset_size / len(df)) * subset_entropy\n",
    "        \n",
    "        # If the calculated entropy is less than the minimum entropy, update the minimum value\n",
    "        if weighted_entropy < min_entropy:\n",
    "            min_entropy = weighted_entropy\n",
    "            best_feature = feature\n",
    "    \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Desision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gini index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a decision tree using Gini index\n",
    "def build_tree_gini(df, target_name=None):\n",
    "    # If all samples have the same target value, create a leaf node with that value\n",
    "    if len(df[target_name].unique()) == 1:\n",
    "        return TreeNode(value=df[target_name].iloc[0])\n",
    "    \n",
    "    # If only one feature is left (excluding the target), create a leaf node with the most frequent target value\n",
    "    if len(df.columns) == 1:\n",
    "        return TreeNode(value=df[target_name].mode()[0])\n",
    "    \n",
    "    # Select the best feature using the Gini index\n",
    "    best_feature = best_feature_gini(df, target_name)\n",
    "    \n",
    "    # Create a decision node with the selected feature\n",
    "    current_node = TreeNode(feature=best_feature)\n",
    "    \n",
    "    # Recursively build subtrees for each value of the selected feature\n",
    "    unique_values = df[best_feature].unique()\n",
    "    for value in unique_values:\n",
    "        subset = df[df[best_feature] == value]\n",
    "        subtree = build_tree_gini(subset, target_name)\n",
    "        current_node.subtrees[value] = subtree\n",
    "    \n",
    "    return current_node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_entropy(df, target_name=None):\n",
    "    # If all samples have the same target value, create a leaf node with that value.\n",
    "    if len(df[target_name].unique()) == 1:\n",
    "        return TreeNode(value=df[target_name].iloc[0])\n",
    "    \n",
    "    # If only one feature remains (excluding the target), create a leaf node with the most frequent target value.\n",
    "    if len(df.columns) == 1:\n",
    "        return TreeNode(value=df[target_name].mode()[0])\n",
    "    \n",
    "    # Select the best feature using entropy.\n",
    "    best_feature = best_feature_entropy(df, target_name)\n",
    "    \n",
    "    # Create a decision node with the selected feature.\n",
    "    current_node = TreeNode(feature=best_feature)\n",
    "    \n",
    "    # Recursively build subtrees for each value.\n",
    "    unique_values = df[best_feature].unique()\n",
    "    for value in unique_values:\n",
    "        subset = df[df[best_feature] == value]\n",
    "        subtree = build_tree_entropy(subset, target_name)\n",
    "        current_node.subtrees[value] = subtree\n",
    "    \n",
    "    return current_node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, data_point):\n",
    "    if tree.value is not None:\n",
    "        return tree.value\n",
    "    \n",
    "    # Recursively traverses the tree\n",
    "    feature = tree.feature\n",
    "    feature_value = data_point[feature]\n",
    "    \n",
    "    if feature_value in tree.subtrees:\n",
    "        return predict(tree.subtrees[feature_value], data_point)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run & accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Done!\n",
      "entropy Done!\n"
     ]
    }
   ],
   "source": [
    "target_name = 'satisfaction'; # Specifying the target column\n",
    "decision_tree_gini = build_tree_gini(data, target_name) # Calculating the tree with Gini index\n",
    "print(\"Gini Done!\")\n",
    "decision_tree_entropy = build_tree_entropy(data, target_name) # Calculating the tree with entropy\n",
    "print(\"entropy Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Accuracy =  93.46 %\n",
      "Entropy Accuracy =  93.32000000000001 %\n"
     ]
    }
   ],
   "source": [
    "# Predicting all test file and saving it for both Gini and Entropy trees\n",
    "predictions_gini = test.apply(lambda row: predict(decision_tree_gini, row), axis=1)\n",
    "predictions_entropy = test.apply(lambda row: predict(decision_tree_entropy, row), axis=1)\n",
    "\n",
    "# Calculating accuracy for both Gini and Entropy\n",
    "accuracy_gini = (predictions_gini == test[target_name]).mean()\n",
    "accuracy_entropy = (predictions_entropy == test[target_name]).mean()\n",
    "\n",
    "print(\"Gini Accuracy = \",(accuracy_gini * 100),\"%\")\n",
    "print(\"Entropy Accuracy = \",(accuracy_entropy * 100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree, depth=0, parent_feature=None, value = None):\n",
    "    if tree is None:\n",
    "        return\n",
    "\n",
    "    if tree.feature is not None:\n",
    "        if parent_feature is not None:\n",
    "            print(\"|    \" * (depth - 1) + f\"{value} -->|-{tree.feature}\")\n",
    "        else:\n",
    "            print(f\"{tree.feature}\")\n",
    "        for value, subtree in tree.subtrees.items():\n",
    "            print_tree(subtree, depth + 1, f\"{tree.feature}\",value=value)\n",
    "\n",
    "    else:\n",
    "        print(\"|    \" * (depth -1),int(value),\"-->\",tree.value)\n",
    "\n",
    "# The following line is to display the tree\n",
    "# print_tree(decision_tree_gini); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * The tree is not shown because it is too big "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finish**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
